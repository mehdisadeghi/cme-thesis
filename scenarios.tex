\chapter{Scenarios}
\label{cha:scenarios}

There are a number of possible use cases in our problem domain. To demonstrate these cases we assume
we have a number of nodes and datasets respectively, but they are not necessarily on the same nodes.
In the following paragraphs we explain possible combinations of operations, nodes and datasets.

\section{Operation}
In every scenario we want to run an operation which could be linear or non-linear.

\subsection{Linear Operation}
Being linear means that the operation
could be broken into its components and then run in parallel or series. Here is algebic notation
of a linear operation which acts on two datasets:

\[ Operation(A + B) = Operation(A) + Operation(B) \]

Being linear or non-linear only matters when we have to operate on more that one dataset.

\subsection{Non-linear Operation}
In contrast to linear there is non-linear operation. This means that this kind of operation has dependant parts and
those parts could not run in parallel:

\[ Operation(A + B) \neq Operation(A) + Operation(B) \]

\section{Datasets}
For each operation we need one or more datasets which my be available on the same node that wants to run the operation
initially or could reside on other nodes. 

\subsection{Input}
Input files are normally not mission critical and could be reproduced.

\subsection{Output}
Operations create output datasets which normally are small in size, threfore we ignore the transfer cost of operation
results in our work.

\subsection{Data Locationing}
We consider three different approaches toward preparing required data for operations.
\subsubsection{Conventional Approach}
in this approach we put the required data on a network file system and all
application instances will access it there. We will utilize an NFS mounted file system.
\subsubsection{Centralized Approach}
in this approach we will have a central instance which will orchestrate operation
delegation and operation output forwarding to other nodes.
\subsubsection{Decentralized Approach}
in this approach we will eliminate the orchestrator node and the network of
application instances should collaborate in a decentralized fashion to keep track of data and control flow for each
task.

For every approach we will run performance tests and we will compare the results.

\subsubsection{Method}
We will discuss scenarios in chapter\ref{cha:scenarios}. For each scenario we will analyze the possible combinations 
of data and operations and we will discuss how to 
deliver the input data and where to store output data. We will discuss workflow management in chapter 
\ref{cha:workflow} and data transfer in chapter\ref{cha:data}.


% TODO: I might need to introduce "Decision Tree"
\section{Decision Making}
The main decision that we need to make at every scenario is whether we should transfer the required data or we
need to delegate the operation to an instance on a node which already has the data. To make a decision we need to
answer a number of questions. First we need to know the location of the data:

\begin{enumerate}
\item Is the data available locally?
\item If not, is the data available on another node? -- Here only the physical location of data matters not the instance
controlling it.
\end{enumerate}

% TODO: Introduce "Decision Metrics"

%In case the mentioned data is available on another nodes we have to answer these questions:
%\begin{enumerate}
%\item What is the cost of data transfer? -- We have to invent an algorithm for this calculation
%\item If data is available on more than one remote node, which one has the minimum transfer cost? -- We might
%introduce multiple strategies and use some heuristics for this selection, simplest form would be random selection,
%another could be asking for an availability metric from the instance and mix it with local calculated availability 
%metric to get a final cost value.
% TODO: We can use "Heartbeat" concept as one of availability metrics
%\item In case it is expensive to transfer the data, can we delegate the operation to an instance on the other node?
%\end{enumerate}



\section{Concrete Scenarios}
We begin with a simple scenario and we gradually add details to it and build new scenarios.

\subsection{Scenario 1}
In this scenario we have a linear operation, e.g. \(Op^A\) on \(Node^A\) which
requires one single dataset such as \( Dataset^1 \) which is available on one of the other peers.

\subsubsection{Conditions} \( Dataset^1 \) is not available on \( Node^A \) and the operation is linear.
\subsubsection{Consequences} With these conditions we either should transfer \( Dataset^1 \)
to local node or in case of availability delegate \(Op^A\) to the node which already has \( Dataset^1 \).

\subsection{Use Case Description}
We have a distributed network of collaborating servers, where in this case, we consider two computers. 
Each server has its own storage and maintains a number of datasets on it. These servers collaborate 
together to accomplish issued commands. User in this case wants to perform one operation on a dataset
that resides only on one of the servers. There are two main assumptions here:
\begin{enumerate}
\item \textbf{The user has neighter a prior knowledge where the data is stored}
\item \textbf{Nor of how many servers are present on the network}
\end{enumerate}

The user connects to one of the servers, which we call a client. This server is assumed to be part 
of the network, though it may not have any local data stores on it. The user issues, interactively
(or non-interactively) a command on a set of data providing some kind of identification. This command
is broadcasted by the client to all servers in the network. All servers receive this command and check
whether they have the data locally. The server which has the data performs the operation and the others
ignore it. The result of the operation in this case, remains on the same server which the original 
dataset was on. 

\begin{itemize}
\item Note: it is assumed that at any instance of time, only one server acts as a client.
\end{itemize}

Moreover we assume the user has already queried the available data in the entire network by 
issueing something like “list datasets” which outputs dataset names and ids.

The following table shows two servers, each has one dataset. The user is connected to S2.\\

\begin{tabular}{ l c r }
\em{Server ID} & \em{ Dataset ID} & \em{ Client} \\
S1 & DS1 & No \\
S2 & DS2 & Yes \\
\end{tabular}\\

Let us assume the data sets are \(10^6\) random numbers.
Let us assume the operation is to transform the real random numbers to a set of [0 or 1 ] depending on whether the number is even or odd. 
This operation is assumed here to be a user defined method that operates on the data set.

\begin{itemize}
\item Note: A dataset can be for example defined as an object that has an id, and a one dimensional array (python list).
\end{itemize}

The user issues the command like this from a python shell: 

\begin{itemize}
\item real2bin(DS1) will result in -> Broadcast(real2bin(DS1))
\item Note: it is assumed that all functions are already defined on all servers, since they execute the same environment.
\end{itemize}

The client broadcasts this function to all servers. Each server will check if the data set with this id exists, if so will run the command. 

This means that each server, especially the client, has to “know about all data sets existing in all servers.
It does not need to have the actual data, but needs to know about it. So that when the user issues the command
above, he/she does not get a “data structure not existent” error from the client, just because the data is not
there. Hence we need some interface, or some wrapper function that checks the argument for the data type, or to 
create some proxy interface from all data to all nodes. 

\section{Assessing Suggested Approaches}
To be able to assess the performance of each given solution to the mentioned scenarios we made a demo application
called \testbf{Konsensus}. The code is available on Github. %TODO add ref here

\subsection{Testing Problems}
Writing tests for a distributed application is not as easy as writing unittests for a normal application. 
Our demo application acts as a server and client at the same time. Moreover we want to launch multiple 
network peers running on one or multiple machines. Testing scenarios on this network is not possible with
normal mocking approaches, because we need to test the behaviour of our solution in a network of collaborating
peers which are not external services, rather the core services of the application.

To overcome testing issues we have to launch the desired number of peers separately and then run our tests 
over them. To make this operation faster we changed the application to make it possible to launch any number
of instances on one machine and we automated this process using a number of scripts. %TODO more details

\subsubsection{Mixing Signals in Greenlets}
We use python Greenlets instead of threads. This means that our demo application runs on only one thread. 
This causes a problem when launching multiple apps all together with one script and inside one thread, that
causes the signals for events spread among all greenlets and make trouble. To avoid this we have to run
each server in a separate processes. Running them inside threads won't help as well because the blinker python
library is threadsafe so it moves signals between threads as well as greenlets.